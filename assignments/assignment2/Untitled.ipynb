{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "## 1.1 Sentiment Analysis (1.5 points)\n",
    "\n",
    "• Given the following short movie reviews and a document D = fast, couple, shoot,\n",
    "fly. Write a python implementation (from scratch!) that compute the most likely\n",
    "class for D. Assume a naive Bayes classifier and use add-1 smoothing for the likelihoods. Each review is labeled with a genre, either comedy or action:\n",
    "1. fun, couple, love, love <b>comedy</b>\n",
    "2. fast, furious, shoot <b>action</b>\n",
    "3. couple, fly, fast, fun, fun <b>comedy</b>\n",
    "4. furious, shoot, shoot, fun <b>action</b>\n",
    "5. fly, fast, shoot, love <b>action</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add our training/test data\n",
    "training_set = [\n",
    "    (['fun', 'couple', 'love', 'love'], 'comedy'),\n",
    "    (['fast', 'furious', 'shoot'], 'action'),\n",
    "    (['couple', 'fly', 'fast', 'fun'], 'comedy'),\n",
    "    (['furious', 'shoot', 'shoot', 'fun'], 'action'),\n",
    "    (['fly', 'fast', 'shoot', 'love'], 'action')\n",
    "]\n",
    "test_statement = ['fast', 'couple', 'shoot', 'fly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('couple', 'comedy'): 2, ('love', 'comedy'): 1, ('fun', 'comedy'): 2, ('shoot', 'action'): 3, ('furious', 'action'): 2, ('fast', 'action'): 2, ('fast', 'comedy'): 1, ('fly', 'comedy'): 1, ('fun', 'action'): 1, ('love', 'action'): 1, ('fly', 'action'): 1}\n",
      "{'comedy': 2, 'action': 3}\n"
     ]
    }
   ],
   "source": [
    "#Initialise some helper variables\n",
    "dataset = set()\n",
    "likelihood_map_data = {}\n",
    "likelihood_map_labels = {}\n",
    "\n",
    "for x0 in [x for x, y in training_set]:\n",
    "    dataset.update(x0)\n",
    "\n",
    "for x, y in training_set:\n",
    "    if y in likelihood_map_labels:\n",
    "        likelihood_map_labels[y] += 1\n",
    "    else:\n",
    "        likelihood_map_labels[y] = 1\n",
    "    for word in set(x):\n",
    "        if(word, y) in likelihood_map_data:\n",
    "            likelihood_map_data[(word, y)] += 1\n",
    "        else:\n",
    "            likelihood_map_data[(word, y)] = 1\n",
    "\n",
    "print(likelihood_map_data)\n",
    "print(likelihood_map_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1081081081081081\n",
      "7\n",
      "0.04562737642585551\n",
      "7\n",
      "0.0064759848893685915\n",
      "7\n",
      "0.0018485712085034274\n",
      "7\n",
      "0.23684210526315788\n",
      "7\n",
      "0.03272727272727272\n",
      "7\n",
      "0.018614270941054806\n",
      "7\n",
      "0.00530425814056284\n",
      "7\n",
      "{'comedy': 0.0018485712085034274, 'action': 0.00530425814056284}\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for label in likelihood_map_labels:\n",
    "    quantity = likelihood_map_labels[label]\n",
    "    likelihood = quantity / len(training_set)\n",
    "    for word in test_statement:\n",
    "        if word in dataset:\n",
    "            l_w0 = 1\n",
    "            if (word, label) in likelihood_map_data:\n",
    "                l_w0 += likelihood_map_data[(word, label)]\n",
    "            \n",
    "            likelihood *= (l_w0 / (likelihood + len(dataset))) \n",
    "            print(likelihood)\n",
    "            print(len(dataset))\n",
    "        results[label] = likelihood\n",
    "        \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.2 Logistic Regression (2 points)\n",
    "Create an implementation (from scratch!) of the Stochastic Gradient Descent\n",
    "Algorithm in Figure 5.5 (Page 86) of the reference book “Speech and Language\n",
    "Processing”.\n",
    "\n",
    "• Note: There are some implementations online. You can use them as a reference\n",
    "but you should try to modify the implementation and show in your report that you\n",
    "understand every step. Also, if you use an implementation online as a reference\n",
    "include in your report which reference you used. Include in your report an example\n",
    "run in the style of the Example in Section 5.4.3 (Page 87) of the reference book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
